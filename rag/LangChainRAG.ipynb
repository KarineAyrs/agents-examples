{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21a20a-22ec-4ce6-b2cc-f1763a175035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain-openai\n",
    "# !pip install langgraph\n",
    "# !pip install \"weaviate-client==3.*\"\n",
    "# !pip install pip-system-certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc88c6ff-a857-49ac-b98d-eb2882b331df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List, Dict, Any, TypedDict\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Weaviate\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langgraph.graph import StateGraph, END\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174340b8-8a91-428a-8c7f-338ef9a61b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d80f391-4d30-4f23-a419-b872f1e90be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/karineayrapetyants/.cache/weaviate-embedded: process ID 53618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "/var/folders/zs/mv0lpz1n46q3ynw23qw42btc0000gn/T/ipykernel_51742/2285041692.py:16: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding=OllamaEmbeddings(\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_98da6e974c83443abfd07128c92cfdb0_W1SYEa6XALDH in 2.965541ms\",\"time\":\"2025-10-17T19:30:07+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:07+03:00\",\"took\":26958}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_b7032b74f12c4bab86b33b848e376645_4efZYv9Vhvmb in 2.906875ms\",\"time\":\"2025-10-17T19:30:08+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8de3340ef927420ab013e7c3e6219573_2splrHLTMnA1 in 2.772875ms\",\"time\":\"2025-10-17T19:30:08+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:08+03:00\",\"took\":73292}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:08+03:00\",\"took\":49333}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_8e493d5d643049be8af1cdea8663d720_9co1WjxiWU5n in 3.012875ms\",\"time\":\"2025-10-17T19:30:08+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:08+03:00\",\"took\":46750}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_f9c34161599d47599966b049fd906790_96zQUNUtOKKi in 7.837459ms\",\"time\":\"2025-10-17T19:30:08+03:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"Completed loading shard langchain_40ab34e5cb364faf86cef4bad7c6bfce_o77gnWnILnQa in 7.904042ms\",\"time\":\"2025-10-17T19:30:08+03:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:08+03:00\",\"took\":3164000}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2025-10-17T19:30:08+03:00\",\"took\":5262917}\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "# Разбиваем документы на куски\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Встраиваем и сохраняем куски в Weaviate\n",
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions()\n",
    ")\n",
    "\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    client=client,\n",
    "    documents=chunks,\n",
    "    # embedding=OpenAIEmbeddings(),\n",
    "    embedding=OllamaEmbeddings(\n",
    "        model=\"hf.co/CompendiumLabs/bge-base-en-v1.5-gguf\",  \n",
    "        base_url=\"http://localhost:11434\"  # Default Ollama server address\n",
    "    ),\n",
    "    by_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa31ca4-c5ec-48bb-80cf-b5313fe2ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/mv0lpz1n46q3ynw23qw42btc0000gn/T/ipykernel_51742/3604983517.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\")\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm = ChatOllama(model=\"hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2adda9ce-2f7f-433f-a047-f5134a2d3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Определяем состояние для LangGraph ---\n",
    "class RAGGraphState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    generation: str\n",
    "\n",
    "# --- 3. Определяем узлы (функции) ---\n",
    "\n",
    "def retrieve_documents_node(state: RAGGraphState) -> RAGGraphState:\n",
    "    \"\"\"Извлекает документы на основе вопроса пользователя.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": \"\"}\n",
    "\n",
    "def generate_response_node(state: RAGGraphState) -> RAGGraphState:\n",
    "    \"\"\"Генерирует ответ, используя LLM на основе извлеченных документов.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Шаблон prompt\n",
    "    template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Форматируем контекст из документов\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Создаем RAG-цепочку\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Вызываем цепочку\n",
    "    generation = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"question\": question, \"documents\": documents, \"generation\": generation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd829189-9cbf-48f6-a551-235c26e810fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Строим граф LangGraph ---\n",
    "\n",
    "workflow = StateGraph(RAGGraphState)\n",
    "\n",
    "# Добавляем узлы\n",
    "workflow.add_node(\"retrieve\", retrieve_documents_node)\n",
    "workflow.add_node(\"generate\", generate_response_node)\n",
    "\n",
    "# Устанавливаем точку входа\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Добавляем рёбра (переходы)\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Компилируем граф\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f32c812-f6c3-4e98-b1a2-58076f10cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Запуск RAG-запроса ---\n",
      "{'retrieve': {'documents': [Document(metadata={'source': './state_of_the_union.txt'}, page_content='Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='But in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='That’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before.')], 'question': 'What did the president say about Justice Breyer', 'generation': ''}}\n",
      "{'generate': {'question': 'What did the president say about Justice Breyer', 'documents': [Document(metadata={'source': './state_of_the_union.txt'}, page_content='Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='But in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='That’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before.')], 'generation': 'President Biden nominated Ketanji Brown Jackson, not Justice Breyer, to fill a vacancy on the Supreme Court.'}}\n",
      "\n",
      "--- Запуск другого RAG-запроса ---\n",
      "{'retrieve': {'documents': [Document(metadata={'source': './state_of_the_union.txt'}, page_content='And it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='I have a better plan to fight inflation. \\n\\nLower your costs, not your wages. \\n\\nMake more cars and semiconductors in America. \\n\\nMore infrastructure and innovation in America. \\n\\nMore goods moving faster and cheaper in America. \\n\\nMore jobs where you can earn a good living in America. \\n\\nAnd instead of relying on foreign supply chains, let’s make it in America. \\n\\nEconomists call it “increasing the productive capacity of our economy.” \\n\\nI call it building a better America.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='So what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='For the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America.')], 'question': 'What did the president say about the economy?', 'generation': ''}}\n",
      "{'generate': {'question': 'What did the president say about the economy?', 'documents': [Document(metadata={'source': './state_of_the_union.txt'}, page_content='And it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='I have a better plan to fight inflation. \\n\\nLower your costs, not your wages. \\n\\nMake more cars and semiconductors in America. \\n\\nMore infrastructure and innovation in America. \\n\\nMore goods moving faster and cheaper in America. \\n\\nMore jobs where you can earn a good living in America. \\n\\nAnd instead of relying on foreign supply chains, let’s make it in America. \\n\\nEconomists call it “increasing the productive capacity of our economy.” \\n\\nI call it building a better America.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='So what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.'), Document(metadata={'source': './state_of_the_union.txt'}, page_content='For the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America.')], 'generation': \"The president's plan aims to boost productivity by making more cars and semiconductors in America, investing more in infrastructure and innovation, and reducing reliance on foreign supply chains. The plan also promises to lower costs, without raising wages, and reduce the national deficit. Additionally, it plans to confirm nominees for the Federal Reserve with a critical role in fighting inflation.\"}}\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Запускаем RAG-приложение ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Запуск RAG-запроса ---\")\n",
    "    query = \"What did the president say about Justice Breyer\"\n",
    "    inputs = {\"question\": query}\n",
    "    for s in app.stream(inputs):\n",
    "        print(s)\n",
    "\n",
    "    print(\"\\n--- Запуск другого RAG-запроса ---\")\n",
    "    query_2 = \"What did the president say about the economy?\"\n",
    "    inputs_2 = {\"question\": query_2}\n",
    "    for s in app.stream(inputs_2):\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff80dd4-b1c0-44c5-b56a-f5a53ec389b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
